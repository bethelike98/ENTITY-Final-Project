{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd5f60b",
   "metadata": {},
   "source": [
    "# Background\n",
    "The objective of this project is to classify the overall sentiment of a tweet's context as neutral, negative, or positive using NLP classifiers. To complete, this project, we are given a dataset of 27,481 tweets, where 22,464 of those tweets were captured as having either a neutral, negative, or positive sentiment. Our goal is to use this training data of ~27.5k tweets to predict the sentiment of the 3,534 tweets in our testing data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c3b2e",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "Importing usual data analytics libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cd699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20b2b5",
   "metadata": {},
   "source": [
    "Importing text, pre-processing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b6c9983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('popular')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbed72b",
   "metadata": {},
   "source": [
    "Importing model-building libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72f8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5ee0e",
   "metadata": {},
   "source": [
    "Importing bag of words libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0523863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c23622",
   "metadata": {},
   "source": [
    "Importing word embedding libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfbcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2447c66",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f9917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"C:/Users/valmh/Documents/GitHub/ENTITY-Final-Project/Data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad2947b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"C:/Users/valmh/Documents/GitHub/ENTITY-Final-Project/Data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0e50b",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015b641",
   "metadata": {},
   "source": [
    "### Sentiment Distribution\n",
    "The dataset is slightly imbalanced. There are more neutral sentiment tweets (11,118) than there are positive (8,582) or negative (7,781). However, the imbalance is not too much that there needs to be a data-balancing technique introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2fbd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='sentiment'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train['sentiment'].value_counts()\n",
    "sns.barplot(x.index, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08fcd962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     11118\n",
      "positive     8582\n",
      "negative     7781\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd87bd5",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "There is just 1 missing value in the text and selected_text columns. Assuming this is the same row, this row will be removed in the data wrangling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d30408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             1\n",
       "selected_text    1\n",
       "sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a64b56",
   "metadata": {},
   "source": [
    "### Number of Words in a Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de454264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.342867422198237\n",
      "13.109881146585877\n",
      "13.473203958360108\n"
     ]
    }
   ],
   "source": [
    "train['word_count'] = train['text'].apply(lambda x: len(str(x).split()))\n",
    "print(train[train['sentiment']=='neutral']['word_count'].mean())\n",
    "print(train[train['sentiment']=='positive']['word_count'].mean())\n",
    "print(train[train['sentiment']=='negative']['word_count'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee898c",
   "metadata": {},
   "source": [
    "Tweets between positive, negative, and neutral sentiments all appear to have around the same number of words. Neutral tweets contain an average of 12.34 words, positive contain an average 13.11 of words, and negative tweets contain an average of 13.47 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2778464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(14,6))\n",
    "train_words=train[train['sentiment']=='neutral']['word_count']\n",
    "ax1.hist(train_words, color=\"red\")\n",
    "ax1.set_title('Neutral Tweets')\n",
    "train_words=train[train['sentiment']=='positive']['word_count']\n",
    "ax2.hist(train_words, color=\"green\")\n",
    "ax2.set_title('Positive Tweets')\n",
    "train_words=train[train['sentiment']=='negative']['word_count']\n",
    "ax3.hist(train_words, color=\"blue\")\n",
    "ax3.set_title('Negative Tweets')\n",
    "fig.suptitle('Words per Tweet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1fbc5",
   "metadata": {},
   "source": [
    "### Number of Characters in a Tweet\n",
    "Neutral tweets contain an average of 65.20 characters, positive tweets contain an average of 70.42 characters, and negative tweets contain an average of 70.49 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df903eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.20120525274329\n",
      "70.41913306921464\n",
      "70.4881120678576\n"
     ]
    }
   ],
   "source": [
    "train['char_count'] = train['text'].apply(lambda x: len(str(x)))\n",
    "print(train[train['sentiment']=='neutral']['char_count'].mean())\n",
    "print(train[train['sentiment']=='positive']['char_count'].mean())\n",
    "print(train[train['sentiment']=='negative']['char_count'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67fab0",
   "metadata": {},
   "source": [
    "## Data Wrangling/Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd783b",
   "metadata": {},
   "source": [
    "### Dropping ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5c57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['text','selected_text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef3ba4",
   "metadata": {},
   "source": [
    "### Punctuation Removal Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "566516e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removepunct(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f9f6d",
   "metadata": {},
   "source": [
    "### Stopword Removal from Texts Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00527cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword(text):\n",
    "    a = [i for i in text.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f567c",
   "metadata": {},
   "source": [
    "### Lemmatization Function\n",
    "Lemmatization reduces a word to its base form by getting rid of its suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da93bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()\n",
    "def position(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def lemmatizer(text):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(text))\n",
    "    a = [wl.lemmatize(tag[0], position(tag[1])) for idx, tag in enumerate(word_pos_tags)]\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b8934",
   "metadata": {},
   "source": [
    "### Combining Functions for Train & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8254160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined(text):\n",
    "    return lemmatizer(stopword(removepunct(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636d08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean'] = train.text.astype(str).str.lower()\n",
    "test['clean'] = test.text.astype(str).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21787343",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean'] = train['clean'].apply(lambda x: combined(x))\n",
    "test['clean'] = test['clean'].apply(lambda x: combined(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ee8ba87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>id respond go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bos bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>interview leave alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>son couldnt put release already buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                                 clean  \n",
       "0                        id respond go  \n",
       "1              sooo sad miss san diego  \n",
       "2                            bos bully  \n",
       "3                interview leave alone  \n",
       "4  son couldnt put release already buy  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0caa835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>last session day httptwitpiccom67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>shanghai also really excite precisely skyscrap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>recession hit veronique branquinho quit compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>happy bday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>httptwitpiccom4w75p like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "\n",
       "                                               clean  \n",
       "0               last session day httptwitpiccom67ezh  \n",
       "1  shanghai also really excite precisely skyscrap...  \n",
       "2  recession hit veronique branquinho quit compan...  \n",
       "3                                         happy bday  \n",
       "4                           httptwitpiccom4w75p like  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def998e",
   "metadata": {},
   "source": [
    "### Tokenizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f20c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "train['tokens'] = train['clean'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c50a080b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>id respond go</td>\n",
       "      <td>[id, respond, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bos bully</td>\n",
       "      <td>[bos, bully]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>interview leave alone</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>son couldnt put release already buy</td>\n",
       "      <td>[son, couldnt, put, release, already, buy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                                 clean  \\\n",
       "0                        id respond go   \n",
       "1              sooo sad miss san diego   \n",
       "2                            bos bully   \n",
       "3                interview leave alone   \n",
       "4  son couldnt put release already buy   \n",
       "\n",
       "                                       tokens  \n",
       "0                           [id, respond, go]  \n",
       "1               [sooo, sad, miss, san, diego]  \n",
       "2                                [bos, bully]  \n",
       "3                   [interview, leave, alone]  \n",
       "4  [son, couldnt, put, release, already, buy]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadcfc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e37c23e",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "Embedding is the process of converting text data to numerical data or vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4a75ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['clean']\n",
    "y_train = train['sentiment']\n",
    "x_test = test['clean']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6b38a",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d491b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tok= [nltk.word_tokenize(i) for i in x_train]  \n",
    "x_test_tok= [nltk.word_tokenize(i) for i in x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82fa8ef",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "457216b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_text_tok']=[nltk.word_tokenize(i) for i in train['clean']]\n",
    "model = Word2Vec(train['clean_text_tok'],min_count=1) \n",
    "\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors)) \n",
    "\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "    def fit(self, X, y):\n",
    "            return self\n",
    "    def transform(self, X):\n",
    "            return np.array([\n",
    "                np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "x_train_vectors_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
    "x_val_vectors_tfidf = tfidf_vectorizer.transform(x_test)\n",
    "    \n",
    "model = Word2Vec(train['clean_text_tok'],min_count=1)     \n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "x_train_vectors_w2v = modelw.transform(x_train_tok)\n",
    "x_val_vectors_w2v = modelw.transform(x_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b301d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "x_train_vectors_tfidf = tfidf_vectorizer.fit_transform(x_train) \n",
    "x_test_vectors_tfidf = tfidf_vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6e860",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0423afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.42      0.54      1001\n",
      "     neutral       0.54      0.81      0.65      1430\n",
      "    positive       0.77      0.56      0.65      1103\n",
      "\n",
      "    accuracy                           0.62      3534\n",
      "   macro avg       0.68      0.60      0.61      3534\n",
      "weighted avg       0.67      0.62      0.62      3534\n",
      "\n",
      "Confusion Matrix: [[ 418  549   34]\n",
      " [ 113 1161  156]\n",
      " [  28  454  621]]\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(x_train_vectors_tfidf, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = nb_tfidf.predict(x_test_vectors_tfidf)\n",
    "y_prob = nb_tfidf.predict_proba(x_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "#fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "#roc_auc = auc(fpr, tpr)\n",
    "#print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e24b6de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text    target sentiment\n",
      "0               Last session day httptwitpiccom67ezh   neutral   neutral\n",
      "1  Shanghai also really excite precisely skyscrap...  positive  positive\n",
      "2  Recession hit Veronique Branquinho quit compan...  negative  negative\n",
      "3                                         happy bday  positive  positive\n",
      "4                         httptwitpiccom4w75p I like   neutral  positive\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing the new dataset\n",
    "test['clean_text'] = test['text'].apply(lambda x: combined(x)) #preprocess the data\n",
    "x_test=test['clean_text'] \n",
    "#converting words to numerical data using tf-idf\n",
    "x_vector=tfidf_vectorizer.transform(x_test)\n",
    "#use the best model to predict 'target' value for the new dataset \n",
    "y_predict = nb_tfidf.predict(x_vector)      \n",
    "y_prob = nb_tfidf.predict_proba(x_vector)[:,1]\n",
    "test['predict_prob']= y_prob\n",
    "test['target']= y_predict\n",
    "final=test[['clean_text','target','sentiment']].reset_index(drop=True)\n",
    "print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f53c88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>27481</td>\n",
       "      <td>27481</td>\n",
       "      <td>27481</td>\n",
       "      <td>27481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27480</td>\n",
       "      <td>22463</td>\n",
       "      <td>3</td>\n",
       "      <td>26876</td>\n",
       "      <td>26876</td>\n",
       "      <td>26876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>11118</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text selected_text sentiment  clean  \\\n",
       "count                                  27480         27480     27481  27481   \n",
       "unique                                 27480         22463         3  26876   \n",
       "top      I`d have responded, if I were going          good   neutral          \n",
       "freq                                       1           199     11118     54   \n",
       "\n",
       "       tokens clean_text_tok  \n",
       "count   27481          27481  \n",
       "unique  26876          26876  \n",
       "top        []             []  \n",
       "freq       54             54  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e281350e-a254-4dfb-be52-3cf80aa1c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbdf41f-f08b-4923-8a8a-de22ca85fccd",
   "metadata": {},
   "source": [
    "### Visualizing sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9228f959-2980-4733-bafa-4da528846eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "train2 = train['clean'].\\\n",
    "   apply(lambda x : polarity(x))\n",
    "train2.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "228e65bb-553f-4449-8d75-3e8eb3bcd678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQZUlEQVR4nO3dfZCdZXnH8e+vRKioJQF2GEzSbkZSLdhaYSdAnbEd0kIQx9AWbagjKWaamTZaX9rR0P6RGYUZmDqlMAo2mpRgqRGpHTKCYopYa6cgi1AwRMoOLyYZkNXwUqVig1f/OHfqIeyS7J7NnoX9fmZ29n6u536ec515Jvnt83J2U1VIkma3n+t3A5Kk/jMMJEmGgSTJMJAkYRhIkoA5/W5gso4++ugaHBzsdxuS9KJyxx13fL+qBvatv2jDYHBwkOHh4X63IUkvKkkeHqvuZSJJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJ4gDCIMnGJI8l+XZX7a+TfCfJ3Un+OcncrnUXJBlJcl+SM7rqy1ptJMnarvqiJLe1+ueSHDqF70+SdAAO5BPIVwEfB67uqm0FLqiqPUkuAS4APpzkeGAFcALwauBfkvxy2+YTwO8AO4Hbk2ypqnuBS4BLq2pzkk8Cq4Are39r4xtce8PB3P2s9tDFZ/W7BUmTsN8zg6r6OrB7n9pXqmpPW7wVWNDGy4HNVfVMVT0IjABL2tdIVT1QVT8BNgPLkwQ4Dbiubb8JOLu3tyRJmqipuGfwbuBLbTwf2NG1bmerjVc/CniiK1j21seUZHWS4STDo6OjU9C6JAl6DIMkfwXsAa6ZmnZeWFWtr6qhqhoaGHjeL92TJE3SpH9raZI/At4KLK2qauVdwMKuaQtajXHqPwDmJpnTzg6650uSpsmkzgySLAM+BLytqp7uWrUFWJHksCSLgMXAN4HbgcXtyaFD6dxk3tJC5BbgnLb9SuD6yb0VSdJkHcijpZ8F/gN4bZKdSVbRebroVcDWJHe1p4Coqm3AtcC9wJeBNVX1bPup/z3ATcB24No2F+DDwAeTjNC5h7BhSt+hJGm/9nuZqKrOHaM87n/YVXURcNEY9RuBG8eoP0DnaSNJUp/4CWRJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkgTM6XcD0oEYXHtDv1t4yXro4rP63YJmAM8MJEn7D4MkG5M8luTbXbUjk2xNcn/7Pq/Vk+TyJCNJ7k5yYtc2K9v8+5Os7KqflOSets3lSTLVb1KS9MIO5MzgKmDZPrW1wM1VtRi4uS0DnAksbl+rgSuhEx7AOuBkYAmwbm+AtDl/3LXdvq8lSTrI9hsGVfV1YPc+5eXApjbeBJzdVb+6Om4F5iY5FjgD2FpVu6vqcWArsKyt+4WqurWqCri6a1+SpGky2XsGx1TVI238KHBMG88HdnTN29lqL1TfOUZ9TElWJxlOMjw6OjrJ1iVJ++r5BnL7ib6moJcDea31VTVUVUMDAwPT8ZKSNCtMNgy+1y7x0L4/1uq7gIVd8xa02gvVF4xRlyRNo8mGwRZg7xNBK4Hru+rntaeKTgGebJeTbgJOTzKv3Tg+HbiprXsqySntKaLzuvYlSZom+/3QWZLPAr8FHJ1kJ52ngi4Grk2yCngYeEebfiPwFmAEeBo4H6Cqdif5KHB7m/eRqtp7U/pP6Tyx9HLgS+1LkjSN9hsGVXXuOKuWjjG3gDXj7GcjsHGM+jDw+v31IUk6ePwEsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJLoMQySfCDJtiTfTvLZJD+fZFGS25KMJPlckkPb3MPa8khbP9i1nwta/b4kZ/T4niRJEzTpMEgyH/gzYKiqXg8cAqwALgEurarjgMeBVW2TVcDjrX5pm0eS49t2JwDLgCuSHDLZviRJE9frZaI5wMuTzAEOBx4BTgOua+s3AWe38fK2TFu/NElafXNVPVNVDwIjwJIe+5IkTcCkw6CqdgEfA75LJwSeBO4AnqiqPW3aTmB+G88HdrRt97T5R3XXx9jmOZKsTjKcZHh0dHSyrUuS9tHLZaJ5dH6qXwS8GngFncs8B01Vra+qoaoaGhgYOJgvJUmzSi+XiX4beLCqRqvqf4EvAG8C5rbLRgALgF1tvAtYCNDWHwH8oLs+xjaSpGnQSxh8FzglyeHt2v9S4F7gFuCcNmclcH0bb2nLtPVfrapq9RXtaaNFwGLgmz30JUmaoDn7nzK2qrotyXXAt4A9wJ3AeuAGYHOSC1ttQ9tkA/CZJCPAbjpPEFFV25JcSydI9gBrqurZyfYlSZq4SYcBQFWtA9btU36AMZ4GqqofA28fZz8XARf10oskafL8BLIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiS6DEMksxNcl2S7yTZnuTUJEcm2Zrk/vZ9XpubJJcnGUlyd5ITu/azss2/P8nKXt+UJGliej0zuAz4clW9DngDsB1YC9xcVYuBm9sywJnA4va1GrgSIMmRwDrgZGAJsG5vgEiSpsekwyDJEcCbgQ0AVfWTqnoCWA5satM2AWe38XLg6uq4FZib5FjgDGBrVe2uqseBrcCyyfYlSZq4Xs4MFgGjwN8nuTPJp5O8Ajimqh5pcx4Fjmnj+cCOru13ttp49edJsjrJcJLh0dHRHlqXJHXrJQzmACcCV1bVG4Ef8bNLQgBUVQHVw2s8R1Wtr6qhqhoaGBiYqt1K0qzXSxjsBHZW1W1t+To64fC9dvmH9v2xtn4XsLBr+wWtNl5dkjRNJh0GVfUosCPJa1tpKXAvsAXY+0TQSuD6Nt4CnNeeKjoFeLJdTroJOD3JvHbj+PRWkyRNkzk9bv9e4JokhwIPAOfTCZhrk6wCHgbe0ebeCLwFGAGebnOpqt1JPgrc3uZ9pKp299iXJGkCegqDqroLGBpj1dIx5hawZpz9bAQ29tKLJGny/ASyJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJHr/RXWS9DyDa2/odwsvWQ9dfNZB2a9nBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJKYgDJIckuTOJF9sy4uS3JZkJMnnkhza6oe15ZG2frBrHxe0+n1Jzui1J0nSxEzFmcH7gO1dy5cAl1bVccDjwKpWXwU83uqXtnkkOR5YAZwALAOuSHLIFPQlSTpAPYVBkgXAWcCn23KA04Dr2pRNwNltvLwt09YvbfOXA5ur6pmqehAYAZb00pckaWJ6PTP4W+BDwE/b8lHAE1W1py3vBOa38XxgB0Bb/2Sb///1MbaRJE2DSYdBkrcCj1XVHVPYz/5ec3WS4STDo6Oj0/WykvSS18uZwZuAtyV5CNhM5/LQZcDcJHv/nOYCYFcb7wIWArT1RwA/6K6Psc1zVNX6qhqqqqGBgYEeWpckdZt0GFTVBVW1oKoG6dwA/mpVvRO4BTinTVsJXN/GW9oybf1Xq6pafUV72mgRsBj45mT7kiRN3Jz9T5mwDwObk1wI3AlsaPUNwGeSjAC76QQIVbUtybXAvcAeYE1VPXsQ+pIkjWNKwqCqvgZ8rY0fYIyngarqx8Dbx9n+IuCiqehFkjRxfgJZkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiR6CIMkC5PckuTeJNuSvK/Vj0yyNcn97fu8Vk+Sy5OMJLk7yYld+1rZ5t+fZGXvb0uSNBG9nBnsAf68qo4HTgHWJDkeWAvcXFWLgZvbMsCZwOL2tRq4EjrhAawDTgaWAOv2BogkaXpMOgyq6pGq+lYb/zewHZgPLAc2tWmbgLPbeDlwdXXcCsxNcixwBrC1qnZX1ePAVmDZZPuSJE3clNwzSDIIvBG4DTimqh5pqx4Fjmnj+cCOrs12ttp49bFeZ3WS4STDo6OjU9G6JIkpCIMkrwT+CXh/VT3Vva6qCqheX6Nrf+uraqiqhgYGBqZqt5I06/UUBkleRicIrqmqL7Ty99rlH9r3x1p9F7Cwa/MFrTZeXZI0TXp5mijABmB7Vf1N16otwN4nglYC13fVz2tPFZ0CPNkuJ90EnJ5kXrtxfHqrSZKmyZwetn0T8C7gniR3tdpfAhcD1yZZBTwMvKOtuxF4CzACPA2cD1BVu5N8FLi9zftIVe3uoS9J0gRNOgyq6htAxlm9dIz5BawZZ18bgY2T7UWS1Bs/gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkZlAYJFmW5L4kI0nW9rsfSZpNZkQYJDkE+ARwJnA8cG6S4/vblSTNHjMiDIAlwEhVPVBVPwE2A8v73JMkzRpz+t1AMx/Y0bW8Ezh530lJVgOr2+IPk9w3Db3129HA9/vdxIHKJf3uYEbwmL34vGiO2RQcr18aqzhTwuCAVNV6YH2/+5hOSYaraqjffejAecxefDxmM+cy0S5gYdfyglaTJE2DmRIGtwOLkyxKciiwAtjS554kadaYEZeJqmpPkvcANwGHABuraluf25opZtVlsZcIj9mLz6w/ZqmqfvcgSeqzmXKZSJLUR4aBJMkwkCQZBpIkDIMZIclgku8kuSbJ9iTXJTk8ydIkdya5J8nGJIe1+RcnuTfJ3Uk+1u/+Z5t2vLYn+VSSbUm+kuTlSV6T5MtJ7kjyb0le1+ZfleScru1/2L/uZ59JHK/XJLm1/bu7cLYcL8Ng5ngtcEVV/QrwFPBB4CrgD6rqV+k8BvwnSY4Cfhc4oap+DbiwT/3OdouBT1TVCcATwO/TeTzxvVV1EvAXwBX9a0/7mMjxugy4rP2729mHXvvCMJg5dlTVv7fxPwBLgQer6r9abRPwZuBJ4MfAhiS/Bzw97Z0KOsfmrja+AxgEfgP4fJK7gL8Dju1LZxrLRI7XqcDn2/gfp6/F/poRHzoTAPt+4OMJ4KjnTep8QG8JnbA4B3gPcNpB7077eqZr/CxwDPBEVf36GHP30H7wSvJzwKEHvTvtayLHa1byzGDm+MUkp7bxHwLDwGCS41rtXcC/JnklcERV3Qh8AHjD9LeqMTwFPJjk7QDp2HtsHgJOauO3AS+b/va0jxc6XrfSuYwEnV+NMysYBjPHfcCaJNuBecClwPl0TmPvAX4KfBJ4FfDFJHcD36Bzb0EzwzuBVUn+E9jGz/4mx6eA32z1U4Ef9ak/Pdd4x+v9wAfbv7Hj6Fyafcnz11HMAEkGgS9W1ev73Ys02yU5HPifqqokK4Bzq+ol/8e2vGcgSc91EvDxJKFz7+7d/W1nenhmIEnynoEkyTCQJGEYSJIwDCRJGAaSJOD/ABwqku8DLs/4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sentiment(x):\n",
    "    if x<0:\n",
    "        return 'neg'\n",
    "    elif x==0:\n",
    "        return 'neu'\n",
    "    else:\n",
    "        return 'pos'\n",
    "    \n",
    "train2=train2.\\\n",
    "   map(lambda x: sentiment(x))\n",
    "\n",
    "plt.bar(train2.value_counts().index,\n",
    "        train2.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588923e-8cd8-412d-a0d3-e1774fbb6655",
   "metadata": {},
   "source": [
    "## VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3da83b53-57aa-4791-9ff9-2e09382599a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\valmh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_score(sent):\n",
    "    # Polarity score returns dictionary\n",
    "    ss = sid.polarity_scores(sent)\n",
    "    #return ss\n",
    "    return np.argmax(list(ss.values())[:-1])\n",
    "\n",
    "train2=train['clean'].\\\n",
    "    map(lambda x: get_vader_score(x))\n",
    "polarity=train2.replace({0:'neg',1:'neu',2:'pos'})\n",
    "\n",
    "plt.bar(polarity.value_counts().index,\n",
    "        polarity.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f781214-bc94-43d5-9931-881af7804f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fb8a9de-22f4-4b98-afea-7afa3a562b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72a90f92-0aef-46fc-b05d-a77605f9e357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>27481</td>\n",
       "      <td>27481</td>\n",
       "      <td>27481</td>\n",
       "      <td>27481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27480</td>\n",
       "      <td>22463</td>\n",
       "      <td>3</td>\n",
       "      <td>26876</td>\n",
       "      <td>26876</td>\n",
       "      <td>26876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>11118</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text selected_text sentiment  clean  \\\n",
       "count                                  27480         27480     27481  27481   \n",
       "unique                                 27480         22463         3  26876   \n",
       "top      I`d have responded, if I were going          good   neutral          \n",
       "freq                                       1           199     11118     54   \n",
       "\n",
       "       tokens clean_text_tok  \n",
       "count   27481          27481  \n",
       "unique  26876          26876  \n",
       "top        []             []  \n",
       "freq       54             54  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a9a46bb-c280-46d8-bd12-d5db6b14de91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>id respond go</td>\n",
       "      <td>[id, respond, go]</td>\n",
       "      <td>[id, respond, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>bos bully</td>\n",
       "      <td>[bos, bully]</td>\n",
       "      <td>[bos, bully]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>interview leave alone</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>son couldnt put release already buy</td>\n",
       "      <td>[son, couldnt, put, release, already, buy]</td>\n",
       "      <td>[son, couldnt, put, release, already, buy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                                 clean  \\\n",
       "0                        id respond go   \n",
       "1              sooo sad miss san diego   \n",
       "2                            bos bully   \n",
       "3                interview leave alone   \n",
       "4  son couldnt put release already buy   \n",
       "\n",
       "                                       tokens  \\\n",
       "0                           [id, respond, go]   \n",
       "1               [sooo, sad, miss, san, diego]   \n",
       "2                                [bos, bully]   \n",
       "3                   [interview, leave, alone]   \n",
       "4  [son, couldnt, put, release, already, buy]   \n",
       "\n",
       "                               clean_text_tok  \n",
       "0                           [id, respond, go]  \n",
       "1               [sooo, sad, miss, san, diego]  \n",
       "2                                [bos, bully]  \n",
       "3                   [interview, leave, alone]  \n",
       "4  [son, couldnt, put, release, already, buy]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26dff02e-ff8c-4754-8d1f-312b0cc3eef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15024/1438226190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'selected_text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "new_df = train[['selected_text', 'sentiment', 'clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70d2ae39-87f3-4e75-8e1a-3bbefdc5f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "# EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4019ab4-2a0a-4b36-b4f6-a7b6bd228aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.selected_text\n",
    "        self.targets = self.data.sentiment\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db2deb6a-a70a-4c93-8be6-37c5aa854491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e6ec43f-d383-4bc7-b91f-a1e54f99ed29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaClass(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0700b9e7-25e5-4615-bab8-ae204e40ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d44259b0-50d0-4aa1-bbe2-840227e84733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcuate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2af410c7-fd8e-497e-b1bb-e4abfb210f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accuracy(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f622a7a-defb-4051-9e9e-4e08f1246396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "18108",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 18108",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15024/1476884055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15024/1472898151.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnb_tr_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 18108"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad0a63-72ea-49f8-ac0a-4727d803b93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d1368-e09e-43b3-b9ff-6e60386be08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
